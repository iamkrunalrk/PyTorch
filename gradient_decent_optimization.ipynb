{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Decent & Optimization\n",
    "\n",
    "Gradient descent is a fundamental optimization algorithm used in training neural networks. It's crucial for updating the model's parameters (weights and biases) to minimize the loss function. In this explanation, we'll delve deep into gradient descent and optimization techniques used in neural networks, with detailed code examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gradient Descent:\n",
    "\n",
    "Gradient descent is an iterative optimization algorithm used to minimize a differentiable loss function by adjusting the model's parameters in the direction of the steepest decrease in the loss. The primary steps of gradient descent are as follows:\n",
    "\n",
    "* Initialize model parameters randomly or with predefined values.\n",
    "* Compute the gradient of the loss function with respect to each parameter.\n",
    "* Update the parameters by moving in the opposite direction of the gradient.\n",
    "* Repeat the process until convergence or for a fixed number of iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Theta:  2.9999999993888893\n"
     ]
    }
   ],
   "source": [
    "# Initializa parameters and hyperparameters\n",
    "learning_rate = 0.1\n",
    "iterations = 100\n",
    "theta = 0 # parameter to be updated\n",
    "loss_history = []\n",
    "\n",
    "def loss_function(theta):\n",
    "    return (theta - 3) ** 2\n",
    "\n",
    "# Gradient Decent Loop\n",
    "for i in range(iterations):\n",
    "    # Computer the gradient of the loss with respect to theta\n",
    "    gradient = 2 * (theta - 3)\n",
    "\n",
    "    # Update theta using the gradient and learning rate\n",
    "    theta -= learning_rate * gradient\n",
    "\n",
    "    # Compute the loss and store it for analysis\n",
    "    current_loss = loss_function(theta)\n",
    "    loss_history.append(current_loss)\n",
    "\n",
    "print(\"Optimal Theta: \", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple illustration of gradient descent, where we update a single parameter `theta` to minimize a quadratic loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimization Techniques:\n",
    "\n",
    "Gradient descent has several variations and optimization techniques to improve convergence and speed up training. Here are some commonly used optimization algorithms:\n",
    "\n",
    "\n",
    "**Stochastic Gradient Descent (SGD)**: It updates the parameters using a single random data point (or a small batch) at a time, making it faster but noisy.\n",
    "\n",
    "**Mini-Batch Gradient Descent**: A compromise between SGD and batch gradient descent, where you update the parameters using a small batch of data points.\n",
    "\n",
    "**Momentum**: Adds momentum to the update rule, which helps the optimizer escape local minima and accelerates convergence.\n",
    "\n",
    "**Adagrad**: Adjusts the learning rate for each parameter based on their historical gradients, enabling adaptive learning rates.\n",
    "\n",
    "**RMSprop**: Similar to Adagrad but uses a moving average of squared gradients, which reduces the learning rate adaptation.\n",
    "\n",
    "**Adam (Adaptive Moment Estimation)**: Combines the advantages of both momentum and RMSprop and is one of the most widely used optimization algorithms in deep learning.\n",
    "\n",
    "In PyTorch, we can easily implement and use these optimization algorithms through the `torch.optim` module. Here's an example of using Adam optimizer in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Theta:  0.9375530481338501\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define model parameter and loss function\n",
    "theta = torch.tensor(0.0, requires_grad=True)\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "# Create an Optimizer with a learning rate \n",
    "optimizer = optim.Adam([theta], lr=0.01)\n",
    "\n",
    "# Training Loop\n",
    "for i in range(iterations):\n",
    "    optimizer.zero_grad() # Zero the gradient\n",
    "    loss = loss_function(theta, torch.tensor(3.0)) # Computer the loss\n",
    "    loss.backward() # Computer the gradient\n",
    "    optimizer.step() # Update parameter\n",
    "\n",
    "print(\"Optimal Theta: \", theta.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we used the `optim.Adam` optimizer to update the parameter `theta` to minimize a mean squared error (MSE) loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
